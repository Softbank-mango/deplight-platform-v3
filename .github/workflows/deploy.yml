name: CI/CD Pipeline

on:
  # Temporarily disabled auto-trigger on push to avoid conflicts with Terraform
  # push:
  #   branches: [main]
  workflow_dispatch:
    inputs:
      environment:
        description: 'Deployment environment'
        required: true
        default: 'dev'
        type: choice
        options:
          - dev
          - staging
          - production
      target_repository:
        description: 'Target repository to deploy (user repo URL)'
        required: false
        type: string
      target_branch:
        description: 'Target repository branch'
        required: false
        default: 'main'
        type: string
      deployment_id:
        description: 'Deployment ID from dashboard'
        required: false
        type: string

permissions:
  id-token: write
  contents: write  # For creating GitHub releases

env:
  AWS_REGION: ap-northeast-2
  ECR_REGISTRY: 513348493870.dkr.ecr.ap-northeast-2.amazonaws.com
  ECR_REPOSITORY: delightful-deploy
  ECS_CLUSTER: delightful-deploy-cluster
  ECS_SERVICE: delightful-deploy-service
  S3_ARTIFACTS_BUCKET: deplight-platform-artifacts-apne2

jobs:
  create-release:
    name: Create GitHub Release
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' && github.event.inputs.target_repository != ''

    outputs:
      release-tag: ${{ steps.create-release.outputs.tag }}
      release-url: ${{ steps.create-release.outputs.url }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Get latest release version
        id: get-version
        run: |
          # Get the latest release tag, or default to v0 if none exist
          LATEST_TAG=$(gh release list --limit 1 --json tagName --jq '.[0].tagName' 2>/dev/null || echo "v0")

          # Extract numeric version (remove 'v' prefix)
          if [ "$LATEST_TAG" = "v0" ]; then
            NEXT_VERSION=1
          else
            CURRENT_VERSION=$(echo $LATEST_TAG | sed 's/v//')
            NEXT_VERSION=$((CURRENT_VERSION + 1))
          fi

          NEW_TAG="v${NEXT_VERSION}"
          echo "new-tag=${NEW_TAG}" >> $GITHUB_OUTPUT
          echo "Next release version: ${NEW_TAG}"
        env:
          GH_TOKEN: ${{ github.token }}

      - name: Create GitHub Release
        id: create-release
        run: |
          REPO_URL="${{ github.event.inputs.target_repository }}"
          REPO_NAME=$(echo $REPO_URL | sed 's|.*/||' | sed 's|\.git$||')
          TAG="${{ steps.get-version.outputs.new-tag }}"

          gh release create "$TAG" \
            --title "Deployment ${TAG} - ${REPO_NAME}" \
            --notes "Automated deployment for ${REPO_NAME} from commit ${{ github.sha }}" \
            --target "${{ github.ref_name }}"

          RELEASE_URL=$(gh release view "$TAG" --json url --jq '.url')

          echo "tag=${TAG}" >> $GITHUB_OUTPUT
          echo "url=${RELEASE_URL}" >> $GITHUB_OUTPUT
          echo "Created release: ${RELEASE_URL}"
        env:
          GH_TOKEN: ${{ github.token }}

  build-and-test:
    name: Build & Test
    runs-on: ubuntu-latest
    needs: [create-release]
    if: always() && (needs.create-release.result == 'success' || needs.create-release.result == 'skipped')

    outputs:
      image-tag: ${{ steps.meta.outputs.image-tag }}
      ecr-repository: ${{ steps.meta.outputs.ecr-repository }}
      app-port: ${{ steps.ai-analysis.outputs.port || '8000' }}
      cpu: ${{ steps.ai-analysis.outputs.cpu || '256' }}
      memory: ${{ steps.ai-analysis.outputs.memory || '512' }}
      release-tag: ${{ needs.create-release.outputs.release-tag }}
      ecs-service-name: ${{ steps.select-service.outputs.service }}
      analysis-id: ${{ steps.ai-analysis.outputs.analysis_id }}

    steps:
      - name: Parse repository URL
        id: parse-repo
        run: |
          TARGET_REPO="${{ github.event.inputs.target_repository }}"

          if [ -n "$TARGET_REPO" ]; then
            # Extract owner/repo from URL if it's a full GitHub URL
            # Supports formats: https://github.com/owner/repo, https://github.com/owner/repo.git
            REPO_PATH=$(echo "$TARGET_REPO" | sed -E 's|https?://github.com/||' | sed 's|\.git$||')
            echo "repository=${REPO_PATH}" >> $GITHUB_OUTPUT
            echo "Parsed repository: ${REPO_PATH}"
          else
            echo "repository=${{ github.repository }}" >> $GITHUB_OUTPUT
            echo "Using default repository: ${{ github.repository }}"
          fi

      - name: Checkout user repository
        if: github.event.inputs.target_repository
        uses: actions/checkout@v4
        with:
          repository: ${{ steps.parse-repo.outputs.repository }}
          ref: ${{ github.event.inputs.target_branch || 'main' }}
          path: user_repo

      - name: Checkout platform repository
        if: ${{ !github.event.inputs.target_repository }}
        uses: actions/checkout@v4
        with:
          repository: ${{ github.repository }}
          ref: ${{ github.ref }}
          path: .

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Ensure DynamoDB tables exist (dev)
        run: |
          set -euo pipefail
          REGION="${{ env.AWS_REGION }}"
          HIST="deplight-platform-deployment-history"
          LOGS="deplight-platform-deployment-logs"

          echo "Ensuring DynamoDB table: $HIST"
          if ! aws dynamodb describe-table --table-name "$HIST" --region "$REGION" >/dev/null 2>&1; then
            aws dynamodb create-table \
              --table-name "$HIST" \
              --attribute-definitions AttributeName=id,AttributeType=S \
              --key-schema AttributeName=id,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region "$REGION"
            aws dynamodb wait table-exists --table-name "$HIST" --region "$REGION"
          fi

          echo "Ensuring DynamoDB table: $LOGS"
          if ! aws dynamodb describe-table --table-name "$LOGS" --region "$REGION" >/dev/null 2>&1; then
            aws dynamodb create-table \
              --table-name "$LOGS" \
              --attribute-definitions AttributeName=deployment_id,AttributeType=S \
              --key-schema AttributeName=deployment_id,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST \
              --region "$REGION"
            aws dynamodb wait table-exists --table-name "$LOGS" --region "$REGION"
          fi

      - name: Analyze user code with Lambda AI
        if: github.event.inputs.target_repository
        id: ai-analysis
        run: |
          echo "üîç Analyzing user repository with AI..."

          # Get file list from user_repo
          cd user_repo
          FILES=$(find . -type f -not -path "./.git/*" | head -100 | jq -R -s -c 'split("\n")[:-1]')

          # Get README if exists and encode safely with jq
          if [ -f README.md ]; then
            README_CONTENT=$(cat README.md | head -100 | jq -Rs .)
          else
            README_CONTENT='""'
          fi

          # Create payload using jq for safe JSON encoding
          PAYLOAD=$(jq -n \
            --arg repo "${{ github.event.inputs.target_repository }}" \
            --arg sha "${{ github.sha }}" \
            --arg branch "${{ github.event.inputs.target_branch }}" \
            --argjson files "$FILES" \
            --argjson readme "$README_CONTENT" \
            '{repository: $repo, commit_sha: $sha, branch: $branch, file_list: $files, readme_content: $readme}')

          # Generate analysis ID based on repo and commit
          ANALYSIS_ID=$(echo -n "${{ github.event.inputs.target_repository }}-${{ github.sha }}" | md5sum | cut -d' ' -f1 | cut -c1-24)
          echo "Analysis ID: $ANALYSIS_ID"

          # Add analysis_id to payload
          PAYLOAD=$(echo "$PAYLOAD" | jq --arg analysis_id "$ANALYSIS_ID" '. + {analysis_id: $analysis_id}')

          # Call Lambda AI asynchronously (no wait for response)
          echo "üîç Triggering async AI analysis..."
          aws lambda invoke \
            --function-name delightful-deploy-ai-analyzer \
            --invocation-type Event \
            --payload "$PAYLOAD" \
            --cli-binary-format raw-in-base64-out \
            --region ap-northeast-2 \
            /tmp/lambda_invoke_response.json

          echo "‚úÖ Lambda invoked asynchronously"

          # Poll S3 for dockerfile (indicates analysis complete)
          S3_BUCKET="${{ env.S3_ARTIFACTS_BUCKET }}"
          S3_DOCKERFILE_KEY="analysis/${ANALYSIS_ID}/dockerfile"
          MAX_WAIT=300  # 5 minutes
          WAIT_TIME=0
          POLL_INTERVAL=10

          echo "‚è≥ Waiting for AI analysis to complete..."
          while [ $WAIT_TIME -lt $MAX_WAIT ]; do
            if aws s3 ls "s3://${S3_BUCKET}/${S3_DOCKERFILE_KEY}" >/dev/null 2>&1; then
              echo "‚úÖ Analysis complete! Files generated in S3."
              break
            fi
            echo "  ‚è≥ Waiting... (${WAIT_TIME}s/${MAX_WAIT}s)"
            sleep $POLL_INTERVAL
            WAIT_TIME=$((WAIT_TIME + POLL_INTERVAL))
          done

          if [ $WAIT_TIME -ge $MAX_WAIT ]; then
            echo "‚ö†Ô∏è Timeout waiting for AI analysis. Proceeding without AI artifacts."
          fi

          # Download terraform_tfvars to extract configuration
          aws s3 cp "s3://${S3_BUCKET}/analysis/${ANALYSIS_ID}/terraform_tfvars" /tmp/terraform.tfvars || true

          # Extract port from terraform_tfvars or use defaults
          APP_PORT=8000
          CPU=256
          MEMORY=512

          # Try to extract port from terraform.tfvars if it exists
          if [ -f /tmp/terraform.tfvars ]; then
            APP_PORT=$(grep -oP 'container_port\s*=\s*\K\d+' /tmp/terraform.tfvars || echo "8000")
            CPU=$(grep -oP 'container_cpu\s*=\s*"\K\d+' /tmp/terraform.tfvars || echo "256")
            MEMORY=$(grep -oP 'container_memory\s*=\s*"\K\d+' /tmp/terraform.tfvars || echo "512")
          fi

          echo "Using configuration: Port=${APP_PORT}, CPU=${CPU}, Memory=${MEMORY}"

          echo "port=${APP_PORT}" >> $GITHUB_OUTPUT
          echo "cpu=${CPU}" >> $GITHUB_OUTPUT
          echo "memory=${MEMORY}" >> $GITHUB_OUTPUT
          echo "analysis_id=${ANALYSIS_ID}" >> $GITHUB_OUTPUT

          echo "‚úÖ Analysis complete: Port=${APP_PORT}, CPU=${CPU}, Memory=${MEMORY}"

          cd ..

      - name: Download AI-generated Dockerfile from S3
        if: github.event.inputs.target_repository
        run: |
          echo "üì• Downloading AI-generated Dockerfile from S3..."
          ANALYSIS_ID="${{ steps.ai-analysis.outputs.analysis_id }}"
          S3_BUCKET="${{ env.S3_ARTIFACTS_BUCKET }}"

          # Download Dockerfile from S3
          aws s3 cp "s3://${S3_BUCKET}/analysis/${ANALYSIS_ID}/dockerfile" ./user_repo/Dockerfile || echo "‚ö†Ô∏è No Dockerfile in S3, will use existing"

          echo "‚úÖ Dockerfile ready"
          ls -la ./user_repo/Dockerfile || echo "No Dockerfile found"

      - name: Download AI-generated Terraform tfvars from S3
        if: github.event.inputs.target_repository
        id: dl-tfvars
        run: |
          echo "üì• Downloading AI-generated Terraform tfvars from S3..."
          ANALYSIS_ID="${{ steps.ai-analysis.outputs.analysis_id }}"
          S3_BUCKET="${{ env.S3_ARTIFACTS_BUCKET }}"
          mkdir -p infrastructure/terraform
          # Try both keys used by the analyzer
          aws s3 cp "s3://${S3_BUCKET}/analysis/${ANALYSIS_ID}/terraform_tfvars" infrastructure/terraform/ai.tfvars || true
          aws s3 cp "s3://${S3_BUCKET}/analysis/${ANALYSIS_ID}/terraform.tfvars" infrastructure/terraform/ai.tfvars || true
          if [ -f infrastructure/terraform/ai.tfvars ]; then
            echo "ai_tfvars=present" >> $GITHUB_OUTPUT
            echo "‚úÖ Downloaded ai.tfvars"
          else
            echo "‚ö†Ô∏è No ai.tfvars found; proceeding with defaults"
          fi

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Detect build context and Dockerfile
        id: detect
        run: |
          if [ -n "${{ github.event.inputs.target_repository }}" ]; then
            BUILD_PATH="user_repo"
          else
            BUILD_PATH="./dashboard"
          fi
          DOCKERFILE_PATH="$BUILD_PATH/Dockerfile"
          echo "build-path=${BUILD_PATH}" >> $GITHUB_OUTPUT
          if [ -f "$DOCKERFILE_PATH" ]; then
            echo "has-dockerfile=true" >> $GITHUB_OUTPUT
            echo "Dockerfile detected at $DOCKERFILE_PATH"
          else
            echo "has-dockerfile=false" >> $GITHUB_OUTPUT
            echo "No Dockerfile at $DOCKERFILE_PATH"
          fi

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Generate image metadata
        id: meta
        run: |
          SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
          IMAGE_TAG="deploy-${SHORT_SHA}"

          # For user apps, use separate ECR repository per app
          if [ -n "${{ github.event.inputs.target_repository }}" ]; then
            # Extract repo name from URL (e.g., "sabill123/fastapi-deploy-test" ‚Üí "fastapi-deploy-test")
            REPO_NAME=$(echo "${{ github.event.inputs.target_repository }}" | sed 's|.*/||' | sed 's|\.git$||' | tr '[:upper:]' '[:lower:]')
            ECR_REPO="user-app-${REPO_NAME}"
            echo "ecr-repository=${ECR_REPO}" >> $GITHUB_OUTPUT

            # Create ECR repository if it doesn't exist
            aws ecr describe-repositories --repository-names "${ECR_REPO}" --region ${{ env.AWS_REGION }} 2>/dev/null || \
              aws ecr create-repository --repository-name "${ECR_REPO}" --region ${{ env.AWS_REGION }}
          else
            # Platform deployment uses default repository
            echo "ecr-repository=${{ env.ECR_REPOSITORY }}" >> $GITHUB_OUTPUT
          fi

          echo "image-tag=${IMAGE_TAG}" >> $GITHUB_OUTPUT
          echo "short-sha=${SHORT_SHA}" >> $GITHUB_OUTPUT

      - name: Build Docker image (Dockerfile)
        if: steps.detect.outputs.has-dockerfile == 'true'
        run: |
          ECR_REPO="${{ steps.meta.outputs.ecr-repository }}"
          docker build -t ${{ env.ECR_REGISTRY }}/${ECR_REPO}:${{ steps.meta.outputs.image-tag }} \
                       -t ${{ env.ECR_REGISTRY }}/${ECR_REPO}:latest \
                       "${{ steps.detect.outputs.build-path }}"

      - name: Install Pack CLI (Buildpacks)
        if: steps.detect.outputs.has-dockerfile == 'false'
        run: |
          PACK_VERSION=0.33.2
          echo "Installing pack v${PACK_VERSION}..."
          curl -sSL -o pack.tgz "https://github.com/buildpacks/pack/releases/download/v${PACK_VERSION}/pack-v${PACK_VERSION}-linux.tgz"
          sudo tar -C /usr/local/bin -xzf pack.tgz pack
          pack version

      - name: Build Docker image (Buildpacks fallback)
        if: steps.detect.outputs.has-dockerfile == 'false'
        run: |
          ECR_REPO="${{ steps.meta.outputs.ecr-repository }}"
          IMAGE="${{ env.ECR_REGISTRY }}/${ECR_REPO}:${{ steps.meta.outputs.image-tag }}"
          pack build "$IMAGE" \
            --path "${{ steps.detect.outputs.build-path }}" \
            --builder paketobuildpacks/builder-jammy-base \
            --env "BP_LOG_LEVEL=info"
          # Also tag latest
          docker tag "$IMAGE" "${{ env.ECR_REGISTRY }}/${ECR_REPO}:latest"

      - name: Run security scan
        run: |
          echo "Running security scan..."
          # Add Trivy or other security scanning here

      - name: Push to ECR
        run: |
          ECR_REPO="${{ steps.meta.outputs.ecr-repository }}"
          docker push ${{ env.ECR_REGISTRY }}/${ECR_REPO}:${{ steps.meta.outputs.image-tag }}
          docker push ${{ env.ECR_REGISTRY }}/${ECR_REPO}:latest

      - name: Update DynamoDB deployment record
        run: |
          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          DEPLOYMENT_ID="deploy-${{ steps.meta.outputs.short-sha }}"

          aws dynamodb put-item \
            --table-name deplight-platform-deployment-history \
            --item "{
              \"id\": {\"S\": \"${DEPLOYMENT_ID}\"},
              \"timestamp\": {\"S\": \"${TIMESTAMP}\"},
              \"repository\": {\"S\": \"${{ github.repository }}\"},
              \"commit_sha\": {\"S\": \"${{ github.sha }}\"},
              \"branch\": {\"S\": \"${{ github.ref_name }}\"},
              \"pusher\": {\"S\": \"${{ github.actor }}\"},
              \"image_tag\": {\"S\": \"${{ steps.meta.outputs.image-tag }}\"},
              \"status\": {\"S\": \"building\"}
            }"

  deploy-infrastructure:
    name: Deploy Infrastructure (Terraform)
    needs: build-and-test
    runs-on: ubuntu-latest
    # Always run Terraform - it will handle both platform and user app deployments

    outputs:
      user_app_endpoint: ${{ steps.tf-outputs.outputs.user_app_endpoint }}
      user_app_service: ${{ steps.tf-outputs.outputs.user_app_service }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: "1.5.0"
          terraform_wrapper: false  # Disable wrapper to get clean outputs

      - name: Terraform Init
        working-directory: ./infrastructure/terraform
        run: terraform init

      - name: Prepare Terraform variables for user app
        id: prepare-vars
        run: |
          if [ -n "${{ github.event.inputs.target_repository }}" ]; then
            # User app deployment
            echo "deploy_user_app=true" >> $GITHUB_OUTPUT

            # Extract and sanitize repo name
            REPO_URL="${{ github.event.inputs.target_repository }}"
            REPO_NAME=$(echo "$REPO_URL" | sed 's|.*/||' | sed 's|\.git$||' | tr '[:upper:]' '[:lower:]')
            DEPLOYMENT_ID="${{ github.run_id }}"

            # Create unique app name
            APP_NAME="user-app-${DEPLOYMENT_ID}"
            echo "app_name=${APP_NAME}" >> $GITHUB_OUTPUT

            # Path prefix for ALB routing
            PATH_PREFIX="app/${DEPLOYMENT_ID}"
            echo "path_prefix=${PATH_PREFIX}" >> $GITHUB_OUTPUT

            # ECR repository URL (without tag)
            ECR_REPO="${{ needs.build-and-test.outputs.ecr-repository }}"
            ECR_URL="${{ env.ECR_REGISTRY }}/${ECR_REPO}"
            echo "ecr_url=${ECR_URL}" >> $GITHUB_OUTPUT

            echo "Deploying user app: ${APP_NAME}"
            echo "Path: /${PATH_PREFIX}/*"
            echo "Image: ${ECR_URL}:${{ needs.build-and-test.outputs.image-tag }}"
          else
            # Platform deployment
            echo "deploy_user_app=false" >> $GITHUB_OUTPUT
            echo "Deploying platform (dashboard)"
          fi

      - name: Terraform Plan
        working-directory: ./infrastructure/terraform
        run: |
          # Base variables for all deployments
          TF_VARS="-var=image_tag=${{ needs.build-and-test.outputs.image-tag }}"
          TF_VARS="$TF_VARS -var=commit_sha=${{ github.sha }}"
          TF_VARS="$TF_VARS -var=container_port=${{ needs.build-and-test.outputs.app-port }}"
          TF_VARS="$TF_VARS -var=container_cpu=${{ needs.build-and-test.outputs.cpu }}"
          TF_VARS="$TF_VARS -var=container_memory=${{ needs.build-and-test.outputs.memory }}"

          # If AI-generated tfvars exists, include it
          if [ -f ai.tfvars ]; then
            TF_VARS="$TF_VARS -var-file=ai.tfvars"
            echo "Using AI-generated tfvars (ai.tfvars)"
          fi

          # Add user app variables if deploying a user app
          if [ "${{ steps.prepare-vars.outputs.deploy_user_app }}" = "true" ]; then
            TF_VARS="$TF_VARS -var=deploy_user_app=true"
            TF_VARS="$TF_VARS -var=user_app_name=${{ steps.prepare-vars.outputs.app_name }}"
            TF_VARS="$TF_VARS -var=user_app_repository_url=${{ github.event.inputs.target_repository }}"
            TF_VARS="$TF_VARS -var=user_app_image=${{ steps.prepare-vars.outputs.ecr_url }}"
            TF_VARS="$TF_VARS -var=user_app_image_tag=${{ needs.build-and-test.outputs.image-tag }}"
            TF_VARS="$TF_VARS -var=user_app_port=${{ needs.build-and-test.outputs.app-port }}"
            TF_VARS="$TF_VARS -var=user_app_cpu=${{ needs.build-and-test.outputs.cpu }}"
            TF_VARS="$TF_VARS -var=user_app_memory=${{ needs.build-and-test.outputs.memory }}"
            TF_VARS="$TF_VARS -var=user_app_path_prefix=${{ steps.prepare-vars.outputs.path_prefix }}"
            TF_VARS="$TF_VARS -var=user_app_alb_name=delightful-deploy-alb"
            TF_VARS="$TF_VARS -var=user_app_ecs_cluster_name=${{ env.ECS_CLUSTER }}"
            TF_VARS="$TF_VARS -var=user_app_security_group_id=${{ secrets.ECS_SECURITY_GROUP }}"
          fi

          # Persist args for Apply step
          echo "$TF_VARS" > tfvars_args

          if [ "${{ steps.prepare-vars.outputs.deploy_user_app }}" = "true" ]; then
            echo "Planning only user_app module with -target to avoid platform resource churn"
            terraform plan $TF_VARS -target=module.user_app -out=tfplan || echo "Plan returned non-zero; will attempt apply with computed vars"
          else
            terraform plan $TF_VARS -out=tfplan
          fi

      - name: Terraform Apply
        working-directory: ./infrastructure/terraform
        run: |
          if [ "${{ steps.prepare-vars.outputs.deploy_user_app }}" = "true" ]; then
            echo "Applying only user_app module with -target (direct apply with vars)"
            ARGS=$(cat tfvars_args 2>/dev/null || true)
            terraform apply -auto-approve $ARGS -target=module.user_app
          else
            terraform apply -auto-approve tfplan
          fi

      - name: Extract Terraform outputs
        id: tf-outputs
        working-directory: ./infrastructure/terraform
        run: |
          if [ "${{ steps.prepare-vars.outputs.deploy_user_app }}" = "true" ]; then
            # Extract user app outputs
            USER_APP_ENDPOINT=$(terraform output -raw user_app_endpoint_url 2>/dev/null || echo "")
            USER_APP_SERVICE=$(terraform output -raw user_app_service_name 2>/dev/null || echo "")

            echo "user_app_endpoint=${USER_APP_ENDPOINT}" >> $GITHUB_OUTPUT
            echo "user_app_service=${USER_APP_SERVICE}" >> $GITHUB_OUTPUT

            echo "User app endpoint: ${USER_APP_ENDPOINT}"
            echo "User app service: ${USER_APP_SERVICE}"
          fi

      - name: Verify infrastructure (ECS services)
        id: infra-check
        run: |
          DASH="delightful-deploy-dashboard-service"
          DEFAULT="${{ env.ECS_SERVICE }}"
          echo "Checking ECS services on cluster: ${{ env.ECS_CLUSTER }}"
          aws ecs describe-services --cluster "${{ env.ECS_CLUSTER }}" --services "$DEFAULT" "$DASH" > /tmp/ecs_services.json || true
          echo "--- describe-services output ---"
          cat /tmp/ecs_services.json || true
          DASH_EXISTS=$(jq -r '.services[] | select(.serviceName=="'"$DASH"'") | .status' /tmp/ecs_services.json 2>/dev/null | wc -l | tr -d ' ')
          DEFAULT_EXISTS=$(jq -r '.services[] | select(.serviceName=="'"$DEFAULT"'") | .status' /tmp/ecs_services.json 2>/dev/null | wc -l | tr -d ' ')
          echo "dashboard-exists=${DASH_EXISTS}" >> $GITHUB_OUTPUT
          echo "default-exists=${DEFAULT_EXISTS}" >> $GITHUB_OUTPUT

      - name: Get ECS Service info
        id: ecs
        run: |
          ECS_INFO=$(aws ecs describe-services \
            --cluster ${{ env.ECS_CLUSTER }} \
            --services ${{ env.ECS_SERVICE }} \
            --query 'services[0]')

          RUNNING_COUNT=$(echo $ECS_INFO | jq -r '.runningCount')
          DESIRED_COUNT=$(echo $ECS_INFO | jq -r '.desiredCount')

          echo "running-count=${RUNNING_COUNT}" >> $GITHUB_OUTPUT
          echo "desired-count=${DESIRED_COUNT}" >> $GITHUB_OUTPUT

  deploy-ecs:
    name: Deploy to ECS (Rolling)
    needs: [build-and-test, deploy-infrastructure]
    if: always() && needs.build-and-test.result == 'success'
    runs-on: ubuntu-latest

    outputs:
      alb-dns: ${{ steps.alb.outputs.dns }}
      url: ${{ steps.alb.outputs.url }}
      deployment-id: ${{ steps.deployment-info.outputs.deployment-id }}

    steps:
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Set deployment info
        id: deployment-info
        run: |
          DEPLOYMENT_ID="${{ github.event.inputs.deployment_id || github.run_id }}"
          echo "deployment-id=${DEPLOYMENT_ID}" >> $GITHUB_OUTPUT
          echo "Deployment ID: ${DEPLOYMENT_ID}"

      # Helper function for logging to DynamoDB
      - name: Log progress - Docker Build Complete
        run: |
          DEPLOYMENT_ID="${{ steps.deployment-info.outputs.deployment-id }}"
          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)

          aws dynamodb put-item \
            --table-name deplight-platform-deployment-logs \
            --item "{
              \"deployment_id\": {\"S\": \"${DEPLOYMENT_ID}\"},
              \"timestamp\": {\"S\": \"${TIMESTAMP}\"},
              \"step\": {\"N\": \"5\"},
              \"message\": {\"S\": \"Docker image built and pushed to ECR\"},
              \"log_type\": {\"S\": \"success\"}
            }" || echo "Warning: Failed to log to DynamoDB"

      - name: Deploy user app (Terraform-managed)
        if: github.event.inputs.target_repository
        id: deploy-user-app
        run: |
          echo "üöÄ User application deployed via Terraform!"
          echo "User apps are now managed by Terraform for better infrastructure consistency."

          DEPLOYMENT_ID="${{ steps.deployment-info.outputs.deployment-id }}"
          ENDPOINT="${{ needs.deploy-infrastructure.outputs.user_app_endpoint }}"
          SERVICE_NAME="${{ needs.deploy-infrastructure.outputs.user_app_service }}"

          # Log: Terraform deployment complete
          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          aws dynamodb put-item \
            --table-name deplight-platform-deployment-logs \
            --item "{
              \"deployment_id\": {\"S\": \"${DEPLOYMENT_ID}\"},
              \"timestamp\": {\"S\": \"${TIMESTAMP}\"},
              \"step\": {\"N\": \"6\"},
              \"message\": {\"S\": \"User app infrastructure created via Terraform\"},
              \"log_type\": {\"S\": \"success\"}
            }" || true

          echo "‚úÖ User app deployed successfully via Terraform!"
          echo "Service: ${SERVICE_NAME}"
          echo "Endpoint: ${ENDPOINT}"
          echo "service-name=${SERVICE_NAME}" >> $GITHUB_OUTPUT
          echo "endpoint=${ENDPOINT}" >> $GITHUB_OUTPUT

      - name: Deploy dashboard (Platform deployment)
        if: ${{ !github.event.inputs.target_repository }}
        id: deploy-dashboard
        run: |
          echo "üé® Deploying platform dashboard..."

          # Get current task definition
          TASK_DEF_ARN=$(aws ecs describe-services \
            --cluster ${{ env.ECS_CLUSTER }} \
            --services delightful-deploy-dashboard-service \
            --query 'services[0].taskDefinition' \
            --output text)

          echo "Current task definition: ${TASK_DEF_ARN}"

          # Describe and prepare new task definition
          aws ecs describe-task-definition \
            --task-definition ${TASK_DEF_ARN} \
            --query 'taskDefinition' > task-def.json

          IMAGE="${{ env.ECR_REGISTRY }}/${{ needs.build-and-test.outputs.ecr-repository }}:${{ needs.build-and-test.outputs.image-tag }}"
          cat task-def.json | jq 'del(.taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, .registeredAt, .registeredBy)' > task-def-clean.json
          cat task-def-clean.json | jq --arg IMG "$IMAGE" '.containerDefinitions[0].image = $IMG' > task-def-updated.json

          # Register new task definition
          NEW_TASK_DEF_ARN=$(aws ecs register-task-definition \
            --cli-input-json file://task-def-updated.json \
            --query 'taskDefinition.taskDefinitionArn' \
            --output text)

          echo "New task definition: ${NEW_TASK_DEF_ARN}"

          # Update dashboard service
          aws ecs update-service \
            --cluster ${{ env.ECS_CLUSTER }} \
            --service delightful-deploy-dashboard-service \
            --task-definition ${NEW_TASK_DEF_ARN} \
            --force-new-deployment

          echo "‚úÖ Dashboard deployment initiated"

      - name: Get ALB endpoint
        id: alb
        run: |
          ALB_DNS=$(aws elbv2 describe-load-balancers \
            --names delightful-deploy-alb \
            --query 'LoadBalancers[0].DNSName' \
            --output text)

          echo "dns=${ALB_DNS}" >> $GITHUB_OUTPUT

          # Set URL based on deployment type
          if [ -n "${{ github.event.inputs.target_repository }}" ]; then
            # User app - use Terraform output
            USER_APP_URL="${{ needs.deploy-infrastructure.outputs.user_app_endpoint }}"
            if [ -z "$USER_APP_URL" ]; then
              # Fallback to deployment ID path if Terraform output not available
              DEPLOYMENT_ID="${{ steps.deployment-info.outputs.deployment-id }}"
              USER_APP_URL="http://${ALB_DNS}/app/${DEPLOYMENT_ID}"
            fi
            echo "url=${USER_APP_URL}" >> $GITHUB_OUTPUT
          else
            # Dashboard
            echo "url=http://${ALB_DNS}/dashboard" >> $GITHUB_OUTPUT
          fi

      - name: Verify AWS deployment (ECS/ALB)
        if: github.event.inputs.target_repository
        id: verify-aws
        run: |
          set -euo pipefail
          DEPLOYMENT_ID="${{ steps.deployment-info.outputs.deployment-id }}"
          SERVICE_NAME="user-app-${DEPLOYMENT_ID}"
          CLUSTER="${{ env.ECS_CLUSTER }}"
          REGION="${{ env.AWS_REGION }}"
          ALB_DNS="${{ steps.alb.outputs.dns }}"

          echo "--- ECS Service ---"
          aws ecs describe-services --cluster "$CLUSTER" --services "$SERVICE_NAME" --region "$REGION" \
            --query 'services[0].{serviceName:serviceName,status:status,desiredCount:desiredCount,runningCount:runningCount,taskDefinition:taskDefinition}' --output table || true

          TASK_DEF_ARN=$(aws ecs describe-services --cluster "$CLUSTER" --services "$SERVICE_NAME" --region "$REGION" --query 'services[0].taskDefinition' --output text || echo "")
          if [ -n "$TASK_DEF_ARN" ] && [ "$TASK_DEF_ARN" != "None" ]; then
            echo "--- ECS Task Definition Image ---"
            aws ecs describe-task-definition --task-definition "$TASK_DEF_ARN" --region "$REGION" \
              --query 'taskDefinition.containerDefinitions[0].image' --output text || true
          fi

          echo "--- ALB Listener Rule for /app/${DEPLOYMENT_ID}/* ---"
          LB_ARN=$(aws elbv2 describe-load-balancers --names delightful-deploy-alb --region "$REGION" --query 'LoadBalancers[0].LoadBalancerArn' --output text)
          LISTENER_ARN=$(aws elbv2 describe-listeners --load-balancer-arn "$LB_ARN" --region "$REGION" --query 'Listeners[0].ListenerArn' --output text)
          aws elbv2 describe-rules --listener-arn "$LISTENER_ARN" --region "$REGION" \
            --query "Rules[?contains(join('', [].Conditions[?Field=='path-pattern'].Values[]), '/app/${DEPLOYMENT_ID}/*')].[Priority,RuleArn]" --output table || true

          echo "--- Target Group Health ---"
          TG_ARN=$(aws elbv2 describe-target-groups --names "user-app-${DEPLOYMENT_ID}-tg" --region "$REGION" --query 'TargetGroups[0].TargetGroupArn' --output text 2>/dev/null || echo "")
          if [ -z "$TG_ARN" ] || [ "$TG_ARN" = "None" ]; then
            TG_ARN=$(aws elbv2 describe-target-groups --region "$REGION" --query "TargetGroups[?contains(TargetGroupName, 'user-app-${DEPLOYMENT_ID}')].TargetGroupArn | [0]" --output text 2>/dev/null || echo "")
          fi
          if [ -n "$TG_ARN" ] && [ "$TG_ARN" != "None" ]; then
            aws elbv2 describe-target-health --target-group-arn "$TG_ARN" --region "$REGION" --query 'TargetHealthDescriptions[*].TargetHealth.State' --output table || true
          else
            echo "Target group not found yet (may still be creating)"
          fi

          echo "--- CloudWatch Log Group exists? ---"
          aws logs describe-log-groups --log-group-name-prefix "/aws/ecs/user-apps/${SERVICE_NAME}" --region "$REGION" --query 'logGroups[*].logGroupName' --output table || true

      - name: Diagnostics (if service not running)
        if: github.event.inputs.target_repository
        run: |
          set -euo pipefail
          DEPLOYMENT_ID="${{ steps.deployment-info.outputs.deployment-id }}"
          SERVICE_NAME="user-app-${DEPLOYMENT_ID}"
          CLUSTER="${{ env.ECS_CLUSTER }}"
          REGION="${{ env.AWS_REGION }}"

          echo "=== ECS Service Events (latest 10) ==="
          aws ecs describe-services \
            --cluster "$CLUSTER" \
            --services "$SERVICE_NAME" \
            --region "$REGION" \
            --query 'services[0].events[0:10].[createdAt,message]' \
            --output table || true

          echo "=== Stopped task (most recent) ==="
          TASK_ARN=$(aws ecs list-tasks \
            --cluster "$CLUSTER" \
            --service-name "$SERVICE_NAME" \
            --desired-status STOPPED \
            --region "$REGION" \
            --query 'taskArns[0]' --output text 2>/dev/null || echo "")
          if [ -n "$TASK_ARN" ] && [ "$TASK_ARN" != "None" ]; then
            aws ecs describe-tasks --cluster "$CLUSTER" --tasks "$TASK_ARN" --region "$REGION" \
              --query 'tasks[].{lastStatus:lastStatus,stoppedReason:stoppedReason,exitCode:containers[0].exitCode,reasonCont:containers[0].reason}' \
              --output table || true
          else
            echo "No stopped tasks found"
          fi

          echo "=== Target Group Detailed Health ==="
          TG_ARN=$(aws elbv2 describe-target-groups --region "$REGION" --query "TargetGroups[?contains(TargetGroupName, 'user-app-${DEPLOYMENT_ID}')].TargetGroupArn | [0]" --output text 2>/dev/null || echo "")
          if [ -n "$TG_ARN" ] && [ "$TG_ARN" != "None" ]; then
            aws elbv2 describe-target-health --target-group-arn "$TG_ARN" --region "$REGION" \
              --query 'TargetHealthDescriptions[].{Target:Target,State:TargetHealth.State,Reason:TargetHealth.Reason,Description:TargetHealth.Description}' \
              --output table || true
          else
            echo "Target group not found for diagnostics"
          fi

          echo "=== Recent container logs (up to 50) ==="
          LOG_GROUP="/aws/ecs/user-apps/${SERVICE_NAME}"
          aws logs filter-log-events --log-group-name "$LOG_GROUP" --region "$REGION" --max-items 50 \
            --query 'events[].message' --output text 2>/dev/null || echo "No logs yet"

      - name: Log progress - Deployment Complete
        run: |
          DEPLOYMENT_ID="${{ steps.deployment-info.outputs.deployment-id }}"
          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          ALB_URL="${{ steps.alb.outputs.url }}"

          aws dynamodb put-item \
            --table-name deplight-platform-deployment-logs \
            --item "{
              \"deployment_id\": {\"S\": \"${DEPLOYMENT_ID}\"},
              \"timestamp\": {\"S\": \"${TIMESTAMP}\"},
              \"step\": {\"N\": \"8\"},
              \"message\": {\"S\": \"Deployment complete! URL: ${ALB_URL}\"},
              \"log_type\": {\"S\": \"success\"}
            }" || true

  smoke-test:
    name: Smoke Tests
    needs: deploy-ecs
    if: always() && needs.deploy-ecs.result == 'success'  # deploy-ecs ÏÑ±Í≥µ ÏãúÏóêÎßå
    runs-on: ubuntu-latest

    steps:
      - name: Install curl
        run: |
          sudo apt-get update
          sudo apt-get install -y curl

      - name: Wait for service warmup
        run: /usr/bin/sleep 30

      - name: Health check (path-aware, 2xx-4xx acceptable)
        run: |
          set -euo pipefail
          BASE_URL="${{ needs.deploy-ecs.outputs.url || format('http://{0}', needs.deploy-ecs.outputs.alb-dns) }}"
          echo "Using base URL: ${BASE_URL}"
          MAX_RETRIES=10
          RETRY_COUNT=0
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Health check attempt $((RETRY_COUNT + 1))/$MAX_RETRIES..."
            for HEALTH_PATH in "/api/health" "/health" "/"; do
              CODE=$(/usr/bin/curl -s -o /dev/null -w "%{http_code}" "${BASE_URL}${HEALTH_PATH}" --max-time 10 || echo 000)
              if [ "$CODE" -ge 200 ] && [ "$CODE" -lt 500 ]; then
                echo "‚úì Health check passed at ${BASE_URL}${HEALTH_PATH} (HTTP $CODE)"
                exit 0
              else
                echo "HTTP $CODE at ${BASE_URL}${HEALTH_PATH}"
              fi
            done
            RETRY_COUNT=$((RETRY_COUNT + 1))
            /usr/bin/sleep 10
          done
          echo "‚úó Health check failed for ${BASE_URL} after $MAX_RETRIES attempts"
          exit 1

      - name: API endpoint test
        run: |
          echo "Testing deployment base URL..."
          BASE_URL="${{ needs.deploy-ecs.outputs.url || format('http://{0}', needs.deploy-ecs.outputs.alb-dns) }}"
          # Ensure trailing slash to match ALB path rule "/app/<id>/*"
          BASE_URL_SLASH="${BASE_URL%/}/"
          /usr/bin/curl -fsS "${BASE_URL_SLASH}" --max-time 10 >/dev/null || echo "base URL not available (may be expected if app has no root)"

          echo "Testing /api/health..."
          /usr/bin/curl -fsS "${BASE_URL%/}/api/health" --max-time 10 >/dev/null || echo "/api/health not available"

  store-artifacts:
    name: Store Deployment Artifacts
    needs: [create-release, build-and-test, deploy-ecs]
    runs-on: ubuntu-latest
    if: success()

    steps:
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Create deployment manifest
        run: |
          RELEASE_TAG="${{ needs.create-release.outputs.release-tag || 'unknown' }}"
          IMAGE_TAG="${{ needs.build-and-test.outputs.image-tag }}"
          REPO_URL="${{ github.event.inputs.target_repository || 'unknown' }}"

          cat > deployment-manifest.json <<EOF
          {
            "deployment_id": "${{ github.run_id }}",
            "release_tag": "${RELEASE_TAG}",
            "release_url": "${{ needs.create-release.outputs.release-url || 'N/A' }}",
            "image_tag": "${IMAGE_TAG}",
            "target_repository": "${REPO_URL}",
            "commit_sha": "${{ github.sha }}",
            "environment": "${{ github.event.inputs.environment || 'dev' }}",
            "app_port": "${{ needs.build-and-test.outputs.app-port }}",
            "cpu": "${{ needs.build-and-test.outputs.cpu }}",
            "memory": "${{ needs.build-and-test.outputs.memory }}",
            "deployed_at": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "deployed_by": "${{ github.actor }}"
          }
          EOF

          echo "Deployment Manifest:"
          cat deployment-manifest.json

      - name: Upload deployment manifest to S3
        run: |
          RELEASE_TAG="${{ needs.create-release.outputs.release-tag || github.run_id }}"
          S3_BUCKET="${{ env.S3_ARTIFACTS_BUCKET }}"
          S3_KEY="deployments/${RELEASE_TAG}/manifest.json"

          aws s3 cp deployment-manifest.json "s3://${S3_BUCKET}/${S3_KEY}"
          echo "Uploaded manifest to s3://${S3_BUCKET}/${S3_KEY}"

      - name: Upload AppSpec to S3
        run: |
          RELEASE_TAG="${{ needs.create-release.outputs.release-tag || github.run_id }}"
          S3_BUCKET="${{ env.S3_ARTIFACTS_BUCKET }}"

          # Download Dockerfile from S3 (generated by AI analyzer)
          aws s3 cp "s3://${S3_BUCKET}/generated/${{ github.sha }}/Dockerfile" ./Dockerfile || echo "Dockerfile not found"

          # Upload to release artifacts
          if [ -f ./Dockerfile ]; then
            aws s3 cp ./Dockerfile "s3://${S3_BUCKET}/deployments/${RELEASE_TAG}/Dockerfile"
            echo "Uploaded Dockerfile to s3://${S3_BUCKET}/deployments/${RELEASE_TAG}/Dockerfile"
          fi

  notify:
    name: Notify Results
    needs: [create-release, build-and-test, deploy-ecs, smoke-test, store-artifacts]
    runs-on: ubuntu-latest
    if: always()

    steps:
      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_ARN }}
          aws-region: ${{ env.AWS_REGION }}
      - name: Determine deployment status
        id: status
        run: |
          if [ "${{ needs.smoke-test.result }}" == "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "emoji=üéâ" >> $GITHUB_OUTPUT
            echo "color=good" >> $GITHUB_OUTPUT
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "emoji=‚ùå" >> $GITHUB_OUTPUT
            echo "color=danger" >> $GITHUB_OUTPUT
          fi

      - name: Send Slack notification
        if: env.SLACK_WEBHOOK_URL != ''
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
        run: |
          PAYLOAD=$(jq -n \
            --arg text "${{ steps.status.outputs.emoji }} Deployment ${{ steps.status.outputs.status }}" \
            --arg repo "${{ github.repository }}" \
            --arg sha "${{ github.sha }}" \
            --arg actor "${{ github.actor }}" \
            --arg status "${{ steps.status.outputs.status }}" \
            --arg color "${{ steps.status.outputs.color }}" \
            --arg url "${{ needs.deploy-ecs.outputs.url }}" \
            '{
              text: $text,
              attachments: [{
                color: $color,
                fields: [
                  {title: "Repository", value: $repo, short: true},
                  {title: "Commit", value: $sha, short: true},
                  {title: "Triggered by", value: $actor, short: true},
                  {title: "Status", value: $status, short: true},
                  {title: "URL", value: $url, short: false}
                ]
              }]
            }')

          curl -X POST -H 'Content-type: application/json' \
            --data "$PAYLOAD" \
            $SLACK_WEBHOOK_URL || echo "Slack notification failed"

      - name: Update DynamoDB deployment status
        run: |
          TIMESTAMP=$(date -u +%Y-%m-%dT%H:%M:%SZ)
          STATUS="${{ steps.status.outputs.status }}"

          # Check if this is a user app deployment
          if [ -n "${{ github.event.inputs.target_repository }}" ]; then
            # User app deployment - create complete record in deployment-history
            DEPLOYMENT_ID="${{ needs.deploy-ecs.outputs.deployment-id }}"
            TARGET_REPO="${{ github.event.inputs.target_repository }}"
            ANALYSIS_ID="${{ needs.build-and-test.outputs.analysis-id }}"
            DEPLOYMENT_URL="${{ needs.deploy-ecs.outputs.url }}"
            IMAGE_TAG="${{ needs.build-and-test.outputs.image-tag }}"

            echo "Saving user app deployment to DynamoDB: ${DEPLOYMENT_ID}"

            aws dynamodb put-item \
              --table-name deplight-platform-deployment-history \
              --item "{
                \"id\": {\"S\": \"${DEPLOYMENT_ID}\"},
                \"deployment_id\": {\"S\": \"${DEPLOYMENT_ID}\"},
                \"repository\": {\"S\": \"${TARGET_REPO}\"},
                \"target_repository\": {\"S\": \"${TARGET_REPO}\"},
                \"commit_sha\": {\"S\": \"${{ github.sha }}\"},
                \"branch\": {\"S\": \"${{ github.event.inputs.target_branch || 'main' }}\"},
                \"status\": {\"S\": \"${STATUS}\"},
                \"timestamp\": {\"S\": \"${TIMESTAMP}\"},
                \"completed_at\": {\"S\": \"${TIMESTAMP}\"},
                \"analysis_id\": {\"S\": \"${ANALYSIS_ID}\"},
                \"deployment_url\": {\"S\": \"${DEPLOYMENT_URL}\"},
                \"image_tag\": {\"S\": \"${IMAGE_TAG}\"},
                \"pusher\": {\"S\": \"${{ github.actor }}\"},
                \"platform_repo\": {\"S\": \"${{ github.repository }}\"}
              }"
          else
            # Platform deployment - update existing record
            SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
            DEPLOYMENT_ID="deploy-${SHORT_SHA}"

            aws dynamodb update-item \
              --table-name deplight-platform-deployment-history \
              --key "{\"id\": {\"S\": \"${DEPLOYMENT_ID}\"}}" \
              --update-expression "SET #status = :status, completed_at = :timestamp, deployment_id = :deployment_id" \
              --expression-attribute-names '{"#status": "status"}' \
              --expression-attribute-values "{
                \":status\": {\"S\": \"${STATUS}\"},
                \":timestamp\": {\"S\": \"${TIMESTAMP}\"},
                \":deployment_id\": {\"S\": \"${DEPLOYMENT_ID}\"}
              }"
          fi

      - name: Create deployment summary
        run: |
          echo "## üöÄ Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ steps.status.outputs.emoji }} ${{ steps.status.outputs.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Image Tag:** \`${{ needs.build-and-test.outputs.image-tag }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**ALB URL:** ${{ needs.deploy-ecs.outputs.url }}" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by:** @${{ github.actor }}" >> $GITHUB_STEP_SUMMARY

      - name: Upload workflow logs to S3
        env:
          GH_TOKEN: ${{ github.token }}
        run: |
          RUN_ID="${{ github.run_id }}"
          REPO="${{ github.repository }}"
          OWNER=$(echo "$REPO" | cut -d'/' -f1)
          REPO_NAME=$(echo "$REPO" | cut -d'/' -f2)
          RELEASE_TAG="${{ needs.create-release.outputs.release-tag || github.run_id }}"
          S3_BUCKET="${{ env.S3_ARTIFACTS_BUCKET }}"

          echo "Downloading GitHub Actions logs for run ${RUN_ID}..."
          curl -sSL -H "Authorization: Bearer ${GH_TOKEN}" -H "Accept: application/vnd.github+json" \
            "https://api.github.com/repos/${OWNER}/${REPO_NAME}/actions/runs/${RUN_ID}/logs" \
            -o workflow-logs.zip || true

          if [ -f workflow-logs.zip ]; then
            aws s3 cp workflow-logs.zip "s3://${S3_BUCKET}/deployments/${RELEASE_TAG}/workflow-logs.zip"
            echo "Uploaded logs to s3://${S3_BUCKET}/deployments/${RELEASE_TAG}/workflow-logs.zip"
          else
            echo "No logs downloaded"
          fi
      - name: Select ECS service (main vs dashboard)
        id: select-service
        run: |
          if [ -n "${{ github.event.inputs.target_repository }}" ]; then
            echo "service=${{ env.ECS_SERVICE }}" >> $GITHUB_OUTPUT
            echo "Selected service: ${{ env.ECS_SERVICE }}"
          else
            echo "service=delightful-deploy-dashboard-service" >> $GITHUB_OUTPUT
            echo "Selected service: delightful-deploy-dashboard-service"
          fi
